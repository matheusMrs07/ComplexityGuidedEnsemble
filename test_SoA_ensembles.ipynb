{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd12231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega alguns agoritmos de ensemble presentes na lib 'imbens' e testa em um dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from imbens.ensemble import (\n",
    "    AdaCostClassifier, \n",
    "    AsymBoostClassifier, \n",
    "    AdaUBoostClassifier, \n",
    "    BalancedRandomForestClassifier,\n",
    "    BalanceCascadeClassifier, \n",
    "    CompatibleAdaBoostClassifier, \n",
    "    CompatibleBaggingClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    "    KmeansSMOTEBoostClassifier,\n",
    "    OverBaggingClassifier,\n",
    "    OverBoostClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    SelfPacedEnsembleClassifier,\n",
    "    SMOTEBaggingClassifier,\n",
    "    SMOTEBoostClassifier,\n",
    "    UnderBaggingClassifier\n",
    ")\n",
    "pd.options.mode.chained_assignment = None  # Disable SettingWithCopyWarning\n",
    "np.random.seed(42)  \n",
    "\n",
    "ensemble_list = [\n",
    "    AdaCostClassifier, \n",
    "    AsymBoostClassifier, \n",
    "    AdaUBoostClassifier, \n",
    "    BalancedRandomForestClassifier,\n",
    "    BalanceCascadeClassifier, \n",
    "    CompatibleAdaBoostClassifier, \n",
    "    CompatibleBaggingClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    "    KmeansSMOTEBoostClassifier,\n",
    "    OverBaggingClassifier,\n",
    "    OverBoostClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    SelfPacedEnsembleClassifier,\n",
    "    SMOTEBaggingClassifier,\n",
    "    SMOTEBoostClassifier,\n",
    "    UnderBaggingClassifier\n",
    "]\n",
    "\n",
    "diretorio = './_extra/imb_multiclass/'\n",
    "base_name = \"glass\"\n",
    "results = []\n",
    "mus = np.linspace(0, 1, 11).tolist()\n",
    "\n",
    "for i in range(1,6):\n",
    "    print(f\"Processing {base_name} - {i}\")\n",
    "    data_train = pd.read_csv( f\"{diretorio}{base_name}/{base_name}-5-{i}tra.dat\"  , header=None, delimiter=',', comment='@') \n",
    "    data_test = pd.read_csv( f\"{diretorio}{base_name}/{base_name}-5-{i}tst.dat\"  , header=None, delimiter=',', comment='@') \n",
    "\n",
    "    data_train = data_train.replace({\"positive\": 1, \"negative\": 0}, regex=True)\n",
    "    data_train = data_train.replace({\"M\":0, \"F\":1, \"I\":2}, regex=True)\n",
    "\n",
    "    data_test = data_test.replace({\"positive\": 1, \"negative\": 0}, regex=True)\n",
    "    data_test = data_test.replace({\"M\":0, \"F\":1, \"I\":2}, regex=True)\n",
    "\n",
    "\n",
    "    np_data_train = data_train.to_numpy()\n",
    "    np_data_test = data_test.to_numpy()\n",
    "\n",
    "    X_train_imb =  np.asarray(np_data_train[:,:-1], dtype=np.float32)\n",
    "    y_train_imb = np.asarray(np_data_train[:,-1], dtype=np.int32)\n",
    "    X_test = np_data_test[:,:-1]\n",
    "    y_test = np_data_test[:,-1]\n",
    "\n",
    "    for ensemble_class in ensemble_list:\n",
    "        ensemble = ensemble_class(\n",
    "            n_estimators=50, random_state=42\n",
    "        )\n",
    "\n",
    "        ensemble.fit(X_train_imb, y_train_imb)\n",
    "        y_pred = ensemble.predict(X_test)\n",
    "\n",
    "        results.append( f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"F1 Scores:\", results)\n",
    "print(\"Média F1:\", np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega alguns agoritmos de ensemble presentes na lib 'imbens' e testa no conjunto de datasets proposto\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from imbens.ensemble import (\n",
    "    AdaCostClassifier, \n",
    "    AsymBoostClassifier, \n",
    "    AdaUBoostClassifier, \n",
    "    BalancedRandomForestClassifier,\n",
    "    BalanceCascadeClassifier, \n",
    "    CompatibleAdaBoostClassifier, \n",
    "    CompatibleBaggingClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    "    KmeansSMOTEBoostClassifier,\n",
    "    OverBaggingClassifier,\n",
    "    OverBoostClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    SelfPacedEnsembleClassifier,\n",
    "    SMOTEBaggingClassifier,\n",
    "    SMOTEBoostClassifier,\n",
    "    UnderBaggingClassifier\n",
    ")\n",
    "import json\n",
    "np.random.seed(42)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "diretorio = '../imb_multiclass/'\n",
    "arquivos = os.listdir(diretorio)\n",
    "print(arquivos)\n",
    "\n",
    "results_f1 = {}\n",
    "\n",
    "results_auc = {}\n",
    "\n",
    "errors = []\n",
    "\n",
    "\n",
    "\n",
    "ensemble_list = [\n",
    "    AdaCostClassifier, \n",
    "    AsymBoostClassifier, \n",
    "    AdaUBoostClassifier, \n",
    "    BalancedRandomForestClassifier,\n",
    "    BalanceCascadeClassifier, \n",
    "    CompatibleAdaBoostClassifier, \n",
    "    CompatibleBaggingClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    "    KmeansSMOTEBoostClassifier,\n",
    "    OverBaggingClassifier,\n",
    "    OverBoostClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    SelfPacedEnsembleClassifier,\n",
    "    SMOTEBaggingClassifier,\n",
    "    SMOTEBoostClassifier,\n",
    "    UnderBaggingClassifier\n",
    "]\n",
    "for base_name in arquivos:\n",
    "# for base_name in [\"autos\"]:\n",
    "\n",
    "        \n",
    "\n",
    "    print(f\"Testando base {base_name}\")\n",
    "    results_f1[base_name] = {}\n",
    "    for ensamble_class in ensemble_list:\n",
    "        results_f1[base_name][ensamble_class.__name__] = []    \n",
    "    \n",
    "\n",
    "    for i in range(1,6):\n",
    "        \n",
    "        \n",
    "        print(f\"Fold {i} de 5 !!!!\")\n",
    "\n",
    "        if os.path.exists(f\"{diretorio}{base_name}/{base_name}-transformed/\"):\n",
    "            file_dir = f\"{base_name}-transformed/\"\n",
    "        else:\n",
    "            file_dir = f\"{base_name}-5-fold/\"\n",
    "        \n",
    "        data_train = pd.read_csv( f\"{diretorio}{base_name}/{file_dir}/{base_name}-5-{i}tra.dat\"  , header=None, delimiter=',', comment='@') \n",
    "        data_test = pd.read_csv( f\"{diretorio}{base_name}/{file_dir}/{base_name}-5-{i}tst.dat\"  , header    =None, delimiter=',', comment='@') \n",
    "    \n",
    "        data_train = data_train.replace({\"positive\": 1, \"negative\": 0}, regex=True)\n",
    "        data_train = data_train.replace({\"M\":0, \"F\":1, \"I\":2}, regex=True)\n",
    "        \n",
    "        data_test = data_test.replace({\"positive\": 1, \"negative\": 0}, regex=True)\n",
    "        data_test = data_test.replace({\"M\":0, \"F\":1, \"I\":2}, regex=True)\n",
    "\n",
    "\n",
    "        np_data_train = data_train.to_numpy()\n",
    "        np_data_test = data_test.to_numpy()\n",
    "        \n",
    "        X_train_imb = np_data_train[:,:-1]\n",
    "        y_train_imb = np.asarray(np_data_train[:,-1], dtype=np.int32)\n",
    "        X_test = np_data_test[:,:-1]\n",
    "        y_test = np_data_test[:,-1]\n",
    "        \n",
    "        for ensemble_class in ensemble_list:\n",
    "            try:\n",
    "                ensemble = ensemble_class(n_estimators=50, random_state=42)\n",
    "                ensemble.fit(X_train_imb, y_train_imb)\n",
    "                y_pred = ensemble.predict(X_test)\n",
    "                results_f1[base_name][ensemble_class.__name__].append(\n",
    "                    f1_score(y_test, y_pred, average=\"weighted\")\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Erro com {ensemble_class.__name__}: {e}\")\n",
    "                results_f1[base_name][ensemble_class.__name__].append(None)\n",
    "                errors.append(f\"{base_name} - {i} - {ensemble_class.__name__}\")\n",
    "\n",
    "    # with open('results/results_SoA_f1_multiclass.json', 'w') as f:\n",
    "    #     json.dump(results_f1, f)\n",
    "\n",
    "    # with open('results/results_new_code_auc_with_hardness_multiclass.json', 'w') as f:\n",
    "    #     json.dump(results_auc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20829a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               AdaCostClassifier  ...  UnderBaggingClassifier\n",
      "autos                   0.001136  ...                0.697726\n",
      "balance                 0.011416  ...                0.784712\n",
      "contraceptive           0.191076  ...                0.530552\n",
      "dermatology             0.224529  ...                0.980328\n",
      "ecoli                   0.021669  ...                0.882319\n",
      "glass                   0.064854  ...                0.693796\n",
      "hayes-roth              0.084246  ...                0.824381\n",
      "lymphography                 NaN  ...                0.742146\n",
      "new-thyroid             0.163580  ...                0.963225\n",
      "pageblocks                   NaN  ...                0.909002\n",
      "penbased                0.278307  ...                0.947012\n",
      "shuttle                      NaN  ...                0.957996\n",
      "thyroid                      NaN  ...                0.961429\n",
      "wine                    0.850401  ...                0.966021\n",
      "yeast                   0.000023  ...                0.528475\n",
      "\n",
      "[15 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "# Armazenará os resultados finais\n",
    "df_medias = pd.DataFrame()\n",
    "\n",
    "for dataset_name, classifiers in results_f1.items():\n",
    "    medias = {}\n",
    "\n",
    "    for clf_name, valores in classifiers.items():\n",
    "\n",
    "        if None in valores: \n",
    "            medias[clf_name] = None\n",
    "\n",
    "        else:\n",
    "            medias[clf_name] = mean(valores)\n",
    "\n",
    "        # # Converter lista para numpy, tratando None como NaN\n",
    "        # arr = np.array(valores, dtype=float)\n",
    "\n",
    "        # # Se todos são NaN → média deve ser None\n",
    "        # if np.isnan(arr).all():\n",
    "        #     medias[clf_name] = None\n",
    "        # else:\n",
    "        #     medias[clf_name] = np.nanmean(arr)\n",
    "\n",
    "    # Criar linha para o dataframe final\n",
    "    df_medias = pd.concat(\n",
    "        [df_medias, pd.DataFrame(medias, index=[dataset_name])]\n",
    "    )\n",
    "\n",
    "# Exibir\n",
    "print(df_medias)\n",
    "\n",
    "df_medias.to_csv(\"summary_SoA_results.csv\", sep=';')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
