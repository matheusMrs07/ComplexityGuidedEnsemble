{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2220ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9500 ± 0.0174\n"
     ]
    }
   ],
   "source": [
    "from complexity_guided_ensemble import ComplexityGuidedEnsemble\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Criar dados\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, \n",
    "                          weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Criar e treinar ensemble\n",
    "ensemble = ComplexityGuidedEnsemble(\n",
    "    n_estimators=10,\n",
    "    complexity_type='overlap',\n",
    "    use_active_learning=True,\n",
    "    n_jobs=-1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(ensemble, X, y, cv=5, scoring='f1_weighted')\n",
    "print(f\"F1: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "# Output: F1: 0.8523 ± 0.0234 ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd12231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing glass - 1\n",
      "Processing glass - 2\n",
      "Processing glass - 3\n",
      "Processing glass - 4\n",
      "Processing glass - 5\n",
      "F1 Scores: [0.7172093023255814, 0.7443947525342876, 0.7704822309473472, 0.5420366455250176, 0.6626117609988578]\n",
      "Média F1: 0.6873469384662183\n"
     ]
    }
   ],
   "source": [
    "#Teste para uma unica base de dados\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from complexity_guided_ensemble import ComplexityGuidedEnsemble\n",
    "\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # Disable SettingWithCopyWarning\n",
    "np.random.seed(42)  \n",
    "\n",
    "# complexity_types = pd.read_csv(\"complex_instances_var_0.1to0.9.csv\", index_col=0)\n",
    "\n",
    "# max_var_complex = complexity_types.idxmax(axis=1)\n",
    "\n",
    "\n",
    "diretorio = './_extra/imb_multiclass/'\n",
    "base_name = \"glass\"\n",
    "results = []\n",
    "mus = np.linspace(0, 1, 11).tolist()\n",
    "\n",
    "for i in range(1,6):\n",
    "    print(f\"Processing {base_name} - {i}\")\n",
    "    if os.path.exists(f\"{diretorio}{base_name}/{base_name}-transformed/\"):\n",
    "            file_dir = f\"{base_name}-transformed/\"\n",
    "    else:\n",
    "        file_dir = f\"{base_name}-5-fold/\"\n",
    "        \n",
    "    data_train = pd.read_csv( f\"{diretorio}{base_name}/{file_dir}/{base_name}-5-{i}tra.dat\"  , header=None, delimiter=',', comment='@') \n",
    "    data_test = pd.read_csv( f\"{diretorio}{base_name}/{file_dir}/{base_name}-5-{i}tst.dat\"  , header    =None, delimiter=',', comment='@')  \n",
    "\n",
    "\n",
    "    np_data_train = data_train.to_numpy()\n",
    "    np_data_test = data_test.to_numpy()\n",
    "\n",
    "    X_train_imb =  np.asarray(np_data_train[:,:-1], dtype=np.float32)\n",
    "    y_train_imb = np.asarray(np_data_train[:,-1], dtype=np.int32)\n",
    "    X_test = np_data_test[:,:-1]\n",
    "    y_test = np_data_test[:,-1]\n",
    "\n",
    "\n",
    "    ensemble = ComplexityGuidedEnsemble(\n",
    "        n_estimators=50,\n",
    "        complexity_type='overlap',\n",
    "        n_jobs=-1,  \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    ensemble.fit(X_train_imb, y_train_imb)\n",
    "    y_pred = ensemble.predict(X_test)\n",
    "\n",
    "    results.append( f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "print(\"F1 Scores:\", results)\n",
    "print(\"Média F1:\", np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testando o algoritomo para todas as bases de dados \n",
    "\n",
    "from complexity_guided_ensemble import ComplexityGuidedEnsemble\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import json\n",
    "np.random.seed(42)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "diretorio = './_extra/imb_multiclass/'\n",
    "arquivos = os.listdir(diretorio)\n",
    "print(arquivos)\n",
    "\n",
    "results_f1 = {}\n",
    "\n",
    "results_auc = {}\n",
    "\n",
    "errors = []\n",
    "\n",
    "\n",
    "for base_name in arquivos[:1]:\n",
    "        \n",
    "\n",
    "    print(f\"Testando base {base_name}\")\n",
    "    results_f1[base_name] = []\n",
    "    # results_auc[base_name] = []\n",
    "    \n",
    "    \n",
    "    for i in range(1,6):\n",
    "        \n",
    "        \n",
    "        print(f\"Fold {i} de 5 !!!!\")\n",
    "\n",
    "        if os.path.exists(f\"{diretorio}{base_name}/{base_name}-transformed/\"):\n",
    "            file_dir = f\"{base_name}-transformed/\"\n",
    "        else:\n",
    "            file_dir = f\"{base_name}-5-fold/\"\n",
    "        \n",
    "        data_train = pd.read_csv( f\"{diretorio}{base_name}/{file_dir}/{base_name}-5-{i}tra.dat\"  , header=None, delimiter=',', comment='@') \n",
    "        data_test = pd.read_csv( f\"{diretorio}{base_name}/{file_dir}/{base_name}-5-{i}tst.dat\"  , header    =None, delimiter=',', comment='@') \n",
    "    \n",
    "\n",
    "\n",
    "        np_data_train = data_train.to_numpy()\n",
    "        np_data_test = data_test.to_numpy()\n",
    "        \n",
    "        X_train_imb = np_data_train[:,:-1]\n",
    "        y_train_imb = np.asarray(np_data_train[:,-1], dtype=np.int32)\n",
    "        X_test = np_data_test[:,:-1]\n",
    "        y_test = np_data_test[:,-1]\n",
    "        \n",
    "        ensemble = ComplexityGuidedEnsemble(\n",
    "            n_estimators=50,\n",
    "            complexity_type='neighborhood',\n",
    "            # hardness_function=max_var_complex[base_name],\n",
    "            n_jobs=-1,  \n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        ensemble.fit(X_train_imb, y_train_imb)\n",
    "        y_pred = ensemble.predict(X_test)\n",
    "        # y_pred_proba = ensemble.predict_proba(X_test)\n",
    "\n",
    "        results_f1[base_name].append( f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "        # results_auc[base_name].append( roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted'))\n",
    "\n",
    "    # with open('results/results_new_code_f1_neighborhood_multiclass_2.json', 'w') as f:\n",
    "    #     json.dump(results_f1, f)\n",
    "\n",
    "    # with open('results/results_new_code_auc_with_hardness_multiclass.json', 'w') as f:\n",
    "    #     json.dump(results_auc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      autos   balance  contraceptive  dermatology     ecoli     glass  \\\n",
      "0  0.774621  0.768056       0.559167     0.914756  0.860073  0.717618   \n",
      "1  0.861025  0.759361       0.531461     0.959190  0.884215  0.730356   \n",
      "2  0.843287  0.826730       0.489512     0.958122  0.870170  0.690928   \n",
      "3  0.877059  0.820146       0.465091     0.944281  0.900420  0.583231   \n",
      "4  0.782532  0.810552       0.512404     0.985827  0.875413  0.679110   \n",
      "\n",
      "   hayes-roth  lymphography  new-thyroid  pageblocks  penbased   shuttle  \\\n",
      "0    0.924897      0.691111     0.820252    0.931864  0.900122  1.000000   \n",
      "1    0.814815      0.731313     0.932325    0.934196  0.932165  0.996560   \n",
      "2    0.769231      0.933814     0.953488    0.929264  0.876102  0.998076   \n",
      "3    0.844600      0.862069     0.928121    0.953327  0.899939  0.995634   \n",
      "4    0.766900      0.865287     0.977442    0.913251  0.890872  0.997694   \n",
      "\n",
      "    thyroid      wine     yeast  \n",
      "0  0.980886  0.972263  0.557838  \n",
      "1  0.981889  0.944444  0.525838  \n",
      "2  1.000000  1.000000  0.526137  \n",
      "3  0.986830  0.971081  0.534848  \n",
      "4  0.980887  0.798415  0.541498  \n",
      "          dataset     media\n",
      "0           autos  0.827705\n",
      "1         balance  0.796969\n",
      "2   contraceptive  0.511527\n",
      "3     dermatology  0.952435\n",
      "4           ecoli  0.878058\n",
      "5           glass  0.680249\n",
      "6      hayes-roth  0.824088\n",
      "7    lymphography  0.816719\n",
      "8     new-thyroid  0.922326\n",
      "9      pageblocks  0.932381\n",
      "10       penbased  0.899840\n",
      "11        shuttle  0.997593\n",
      "12        thyroid  0.986098\n",
      "13           wine  0.937241\n",
      "14          yeast  0.537232\n"
     ]
    }
   ],
   "source": [
    "# Organizando os resultados de todas as bases \n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 1. Ler o arquivo .json\n",
    "with open(\"results/results_new_code_f1_error_rate_multiclass.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Converter para DataFrame (cada chave vira uma coluna)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 3. Calcular a média de cada coluna\n",
    "df_medias = df.mean().reset_index()\n",
    "df_medias.columns = [\"dataset\", \"media\"]\n",
    "\n",
    "print(df)\n",
    "print(df_medias)\n",
    "\n",
    "# 4. (Opcional) salvar em CSV ou outro formato\n",
    "df_medias.to_csv(\"medias_datasets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c28b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatena o resultado das 3 variações de medidas de complexidade usadas no modelo\n",
    "\n",
    "complexities = [\"error_rate\", \"overlap\", \"neighborhood\"]\n",
    "\n",
    "df_medias = pd.DataFrame()\n",
    "\n",
    "for comp in complexities:\n",
    "    with open(f\"results/results_new_code_f1_{comp}_multiclass.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    results_pd = pd.DataFrame(results)\n",
    "    df_medias[comp] = results_pd.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67765cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medias.to_csv(\"summary_results_new_code_complexities.csv\", sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
